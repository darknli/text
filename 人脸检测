1 项目描述    APP美颜中很多特效（诸如瘦脸、大眼、美瞳)都需要做人脸检测,获得面部位置,甚至眼睛、鼻子、嘴巴、眉毛等位置.  
  美颜sdk的流程大概是检测->跟踪->关键点.检测器负责给第一帧出初始框,后面每一帧的该人脸id的框都将由跟踪器给出,通过人脸框裁剪出人脸,
  送入关键点模型得到最终面部关键点.2 数据    主要用到的是Wider,也有其他数据集作为辅助,比如celeba、retinaface、wflw等.3 检测 
     由于移动端画面是16:9,因此输入尺寸是320×180.
	* mtcnn：第一版所用模型,fddb的AUC是89.7.
	* ssd：第二版所用模型,fddb的AUC是93.9.

4 跟踪
	* onet：第一版的mtcnn中的第三个model.将检测给出的人脸box向外扩大1.5倍,将图片缩放到48×48,然后送入onet给出跟踪结果.
	* ssd：用检测做跟踪.将检测给出的人脸框向外扩大一倍的边长.然后将图片缩放到49×49,送到ssd里,只取前面的小anchor结果,最大anchor尺寸
	
	是64.之前考虑过KCF、mossia、稀疏光流等,都没有能采用：KCF是性能不足以流畅地在低端手机上运行；mossia效果太差；稀疏光流很难自我修正,人脸消失之后框会留在画面里,需要关键点给出一个人脸概率,但如果靠关键点的话又很容易导致导致很多困难的人脸被误杀.



5 关键点    采用pfld,这部分不太了解.6 工程向优化    以下优化皆是第二版优化：6.1 采用ssd检测,输入尺寸320x180    优化点如下：1)大面积显示
原则：为保证关键点和跟踪质量,当人脸进入屏幕的比例大于0.55时才会开启跟踪并准备显示.2)慢显示：目的：减缓人脸处在比较难检测的姿势不会时现时隐.方法：人脸
框持续检出一段时间后才会显示出来.3)横竖屏检测目的：减少横竖屏切换时带来的resize开销.方法：提前准备两套session和anchor,并及时释放model.6.2 以下优化采用s
sd检测,输入尺寸是49x49.
优化点如下（以下阈值s均不是同一个数)：    1
)人脸保持目的：防止人脸框时现时隐的问题.方法：当人脸分数小于阈值s时,保持上一
帧的人脸框和关键点.    2)人脸框防抖目的：减缓人脸框和关键点抖动.方法：当前后两帧的人脸框的绝对误差（左上
右下两个点,合计四个数的绝对误差
取最大值)小于阈值s1时,保持
上一帧的人脸框；当方差大于s1小于s2时,取前后帧的人脸框
均值.    3)人脸跟踪裁剪框防抖目的：防止人脸在比较难的情况大幅度晃动.方法：前后帧送检到跟踪器的人脸裁剪位置的距离（分别
求出前后帧的人脸框左上点距离位移和右下点距离位置,取最小值)小于一定阈值s时,保持上一帧的裁剪位置.ps：跟人脸框的策略不同,裁剪
框防抖可以把阈值调更高,容忍更大的范围,且用最小位移作为对比标准可以有效的解决某些比较难的场景,人脸框下的下部分疯狂上下抖动.    4)偏移量
最小原则目的：解决检测出两张人脸,并且将另一张人脸当成该face id的人脸.方案：取与上帧人脸框中心点偏移量最小的
人脸框.6.3 关键点    输入尺寸1
12x1121)关键点防抖目的：缓解关键点抖动.方法：当前后帧的位移小于阈值s,上一帧的权重是0.3,本帧的权重是0.7,加权作为最终关
键点.2)大角度旋转&&小角度归正目的：解决每帧旋转带来的抖动.方法：当角度大于阈值s时,开启人脸旋转；当上一帧角度是0,且本帧角度小于阈值s,将角度
变为0.3)边缘角度不更新：防止在边缘时关键点不对导致的角度计算错误.6.4 整体    整体架构的优化：1)旋转跟踪：解决人脸角度较大时,人脸检测模块效果差的
问题.2)严检宽跟目的：防止人脸框频繁闪动.方案：提高检测的阈值；当人脸框和关键点没有符合显示条件的时候提高跟踪阈值,符合显示条件之后,降低跟踪阈值.
7 附录7.1 mtcnn做过的实验最终从FDDB的AP89.7优化到92.1（和全模型的mtcnn持平),优化如下：
	* 数据方面

		* 大部分人脸在图中央,占2/3的位置：考虑到卷积特性,感受野越中心权重越多,效果越好.
		* 提高最小脸尺寸到40：widerface里的图片本身并不清晰,导致小脸人脸特征非常少,使模型的准确率下降.
		* 根据宽高比选择不同正负样本iou阈值：宽高比越接近1的样本越容易裁到iou比较大的图片,这说明长宽比不同用同一套iou
		阈值来判定正负样本不合理,因此采用了两套阈值,宽高比接近1的人脸的正样本iou阈值高一些,不接近的要低一些.
		* 对数据做随机一定比例涂黑：为了使模型在图像边缘或遮挡等情况依然可以检出人脸,把训练数据做随机涂黑,随机(1-4)边涂黑,
		概率依次减少.
	* 模型训练方面
	

		* 关键点分支的消融实验：只有onet加入关键点分支有效果提升,pnet和rnet都不应加入关键点loss.
		* 加入max-out：为了提高召回率,把正类分为多类,再做一个max-out,将结果和负类的分支做softmax,结果是没有提升.
		* 探索了三个网络线下hard样本挖掘的必要性：pnet不做hard样本挖掘反而效果更好.
		* 更换pnet输入尺寸,因为卷积步长2的时候向下取整,导致[19,22]最后输出都是1x1的feature map,从20改成[19,22]的随机裁剪.
	* 模型预测方面

		* 解决了之前的bug：pnet和rnet的nms是对anchor做的,现在改成了对最终回归结果做.

7.2 关于ssd    https://zhuanlan.zhihu.com/p/59101820
